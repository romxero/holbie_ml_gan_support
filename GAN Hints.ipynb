{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7a0a24",
   "metadata": {},
   "source": [
    "# GAN Help/Hints\n",
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187749e",
   "metadata": {},
   "source": [
    "## Have we used the Framework?\n",
    "Check this link: <https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7deeb",
   "metadata": {},
   "source": [
    "**Creaing a Generator**\n",
    "\n",
    "\n",
    "###  0. Generator\n",
    "* Write a subclass that defines the generator:\n",
    "    `class Generator(nn.Module):`\n",
    "* Define the `__init__` construct with these parameters:\n",
    "`(self, input_size, hidden_size, output_size)`\n",
    "* Make sure you define the feed-forward function inside of the class\n",
    "    `def forward(self, x):`\n",
    "* The network should have three layers and two `tanh` activation functions after the first and second layer.\n",
    "* The layers and activation functions should be contained inside of a `nn.Sequential` wrapper class.\n",
    "\n",
    "\n",
    "```\n",
    "student@holbie-ml:~/pytorch$ cat << EOF > ./0-main.py \n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "genTester = __import__('0-generator').Generator\n",
    "\n",
    "G_Test = genTester(1,1,1)\n",
    "\n",
    "print(G_Test)\n",
    "\n",
    "EOF\n",
    "\n",
    "student@holbie-ml:~/pytorch$ python3 ./0-main.py \n",
    "Generator(\n",
    "  (main): Sequential(\n",
    "    (0): Linear(in_features=1, out_features=1, bias=True)\n",
    "    (1): Tanh()\n",
    "    (2): Linear(in_features=1, out_features=1, bias=True)\n",
    "    (3): Tanh()\n",
    "    (4): Linear(in_features=1, out_features=1, bias=True)\n",
    "  )\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03b9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17794e",
   "metadata": {},
   "source": [
    "## Changes\n",
    "### Task 2\n",
    "    Task 2 is a little unclear. Instead of creating a single function, we will create two tasks out of this one. We will have it be two different functions entirely. Or We can actually just take the task out and combine them inside of the trainting task. \n",
    "\n",
    "The mean and standard deviation can be global variables to assist here. \n",
    "\n",
    "Mean = 0\n",
    "StdDev = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f8a66",
   "metadata": {},
   "source": [
    "### Sampler for Generator\n",
    "```\n",
    "aTorchTensorObjectToTrainWith = torch.rand(m, n)\n",
    "```\n",
    "### 'm' should be the batch size, 'n' should be the input size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b0a46",
   "metadata": {},
   "source": [
    "### Sampler for Discriminator\n",
    "```\n",
    "anotherTorchTensorObjectToTrainWith = torch.Tensor(np.random.normal(mu, sigma, (1, n)))\n",
    "```\n",
    "### 'mu' should be the mean, 'sigma' should be standard deviation, 'n' should be the input size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b0b0a",
   "metadata": {},
   "source": [
    "### Train Generator Examples with sampling\n",
    "\n",
    "Here is an example of the Train Generator object with sampling happening insisde of it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2549cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(Gen,Dis, gInputSize, mbatchSize, steps, optimizer, crit):\n",
    "                \n",
    "        for g_index in range(steps):\n",
    "            Gen.zero_grad(set_to_none=False)\n",
    "        \n",
    "            gen_input = torch.rand(mbatchSize, gInputSize)\n",
    "            g_fake_data = Gen(gen_input)\n",
    "            dg_fake_decision = Dis(processMoments(g_fake_data.t()))\n",
    "            g_error = crit(dg_fake_decision, Variable(torch.ones([1]).to(mainComputeDevice)))  \n",
    "            \n",
    "            g_error.backward()\n",
    "            optimizer.step()  \n",
    "            return g_error,g_fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431390e",
   "metadata": {},
   "source": [
    "### Getting moments:\n",
    "\n",
    "Just remember the moments are:\n",
    "* mean\n",
    "* variance\n",
    "* skewness\n",
    "* kurtosis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea9dc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMoments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11b90d",
   "metadata": {},
   "source": [
    "### Train Gan example below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "519d6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan():\n",
    "\n",
    "    g_input_size = 1   # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5  # Generator complexity\n",
    "    g_output_size = 1  # Size of generated output vector\n",
    "    minibatch_size =  500 # Minibatch size - cardinality of distributions\n",
    "    d_input_size = 4 #descriminator input size\n",
    "    d_hidden_size = 10 # Discriminator complexity\n",
    "    d_output_size = 1  # Single dimension for 'real' vs. 'fake' classification\n",
    "    num_epochs = 50\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    #learning rate and momentum\n",
    "    learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_sub_data, d_real_data, d_fake_data, g_fake_data = None, None, None, None\n",
    "\n",
    "\n",
    "    G = Generator2(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size)\n",
    "    D = Discriminator2(input_size=d_input_size,\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size)\n",
    "                      \n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    \n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    #place it to a gpu hopefully\n",
    "    G.to(mainComputeDevice)\n",
    "    D.to(mainComputeDevice)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        dre, dfe, d_fake_data, d_real_data = train_dis(G,D,d_input_size,g_input_size, minibatch_size, d_steps, d_optimizer, criterion)\n",
    "        ge, g_fake_data = train_gen(G,D,g_input_size, minibatch_size, g_steps, g_optimizer, criterion)\n",
    "    return g_fake_data\n",
    "\n",
    "#fakeData = train_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79299597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
